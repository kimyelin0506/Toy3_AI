# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics import classification_report, confusion_matrix

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

from pre_women_body_type import X_train, X_test, y_train, y_test, y_encoded, le_body
"""
[ë”¥ëŸ¬ë‹ ì‹ ê²½ë§ ëª¨ë¸(MLP)ì„ ë§Œë“¤ì–´ì„œ, ì‚¬ëŒ ì²´í˜•(body type)ì„ ë¶„ë¥˜í•˜ëŠ” ê²ƒ]
<ì „ì²´ íë¦„ ìš”ì•½>
(1) í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
- numpy: ìˆ˜ì¹˜ ê³„ì‚°ìš©
- matplotlib/seaborn: ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
- sklearn: í‰ê°€ ì§€í‘œ (confusion matrix, classification report)
- keras: ë”¥ëŸ¬ë‹ ëª¨ë¸ êµ¬ì¶•
- ë¯¸ë¦¬ ì „ì²˜ë¦¬í•´ë†“ì€ X_train, X_test ë“± ë°ì´í„°ì…‹ ê°€ì ¸ì˜´.

(2) ì‹ ê²½ë§ ëª¨ë¸(MLP) ë§Œë“¤ê¸°
- Sequential ëª¨ë¸: í•œ ì¸µì”© ìˆœì„œëŒ€ë¡œ ìŒ“ëŠ” ë°©ì‹
    - ì²« ë²ˆì§¸ Dense ì¸µ: 128ê°œì˜ ë‰´ëŸ°, ReLU í™œì„±í™”
    - Dropout(0.3): 30% ëœë¤ìœ¼ë¡œ ë…¸ë“œ ë„ê¸° (ê³¼ì í•© ë°©ì§€)
    - ë‘ ë²ˆì§¸ Dense ì¸µ: 64ê°œ ë‰´ëŸ°, ReLU
    - ë˜ Dropout
    - ë§ˆì§€ë§‰ Dense ì¸µ: í´ë˜ìŠ¤ ìˆ˜ë§Œí¼ ì¶œë ¥, Softmax (ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜)
    - ìš”ì•½: ì‹¬í”Œí•œ MLP ì‹ ê²½ë§
- ëª¨ë¸ ì»´íŒŒì¼
    - adam: ìµœì í™” ì•Œê³ ë¦¬ì¦˜
    - sparse_categorical_crossentropy: ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ìš© loss í•¨ìˆ˜ (ë ˆì´ë¸”ì´ one-hot encodingì´ ì•„ë‹ˆë¼ ì •ìˆ˜í˜•ì¼ ë•Œ ì‚¬ìš©)
    - metrics=['accuracy']: ì •í™•ë„ í™•ì¸

(3) ëª¨ë¸ í•™ìŠµ (fit)
- early_stopping: validation lossê°€ 5ë²ˆ ì—°ì† ì¢‹ì•„ì§€ì§€ ì•Šìœ¼ë©´ í•™ìŠµ ì¤‘ë‹¨ (ê³¼ì í•© ë°©ì§€)
- history: í•™ìŠµ ê³¼ì • ì €ì¥ (loss/accuracy ê¸°ë¡)

(4) ëª¨ë¸ í‰ê°€ (confusion matrix, classification report, F1 score)
- ì˜ˆì¸¡ ê²°ê³¼ í™•ë¥  â†’ ê°€ì¥ ë†’ì€ í™•ë¥  í´ë˜ìŠ¤ë¥¼ ì„ íƒ.
- precision / recall / f1-score ì¶œë ¥í•´ì„œ ì„±ëŠ¥ í‰ê°€.
- confusion matrix ì‹œê°í™”: ì–´ë–¤ í´ë˜ìŠ¤ë¥¼ ì˜ ë§ì·„ê³ , í—·ê°ˆë ¸ëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ í™•ì¸.
- weighted F1 score ê³„ì‚°í•´ì„œ ì „ì²´ì ì¸ ëª¨ë¸ ì„±ëŠ¥ í™•ì¸.

(5) ê²°ê³¼ ì‹œê°í™” (loss/accuracy ê·¸ë˜í”„)
- Overfittingì´ ìˆëŠ”ì§€/ì„±ê³µì ìœ¼ë¡œ í•™ìŠµí–ˆëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ í™•ì¸.
"""
"""
1. ì™œ Dropoutì„ 2ë²ˆì´ë‚˜ ë„£ì—ˆì„ê¹Œ?
ğŸ‘‰ ê³¼ì í•©(Overfitting)ì„ ë°©ì§€í•˜ë ¤ê³ .
Dropoutì€ í•™ìŠµí•  ë•Œ ëœë¤í•˜ê²Œ ì¼ë¶€ ë‰´ëŸ°ì„ êº¼ë²„ë ¤ì„œ ëª¨ë¸ì´ íŠ¹ì • ë‰´ëŸ°ì— ê³¼í•˜ê²Œ ì˜ì¡´í•˜ì§€ ëª»í•˜ê²Œ ë§‰ì¤Œ
ì²« ë²ˆì§¸ Dense(128 ë‰´ëŸ°) ë’¤ì—ì„œ í•œ ë²ˆ
ë‘ ë²ˆì§¸ Dense(64 ë‰´ëŸ°) ë’¤ì—ì„œ í•œ ë²ˆ
2ë²ˆ ë„£ì€ ì´ìœ ëŠ”: "ë‘ ê°œì˜ í° Dense ë ˆì´ì–´ ê°ê°ì—ì„œ ê³¼ì í•©ì„ ë§‰ê¸° ìœ„í•´ì„œ"
<ìš”ì•½>
Dense ë ˆì´ì–´ë§ˆë‹¤ ë³µì¡ë„ê°€ ë†’ì•„ì§€ë‹ˆê¹Œ
ê³¼ì í•© ë§‰ìœ¼ë ¤ê³  Dropoutì„ ê° ë ˆì´ì–´ ë’¤ì— ë”°ë¡œ ë„£ì€ ê²ƒ
(íŠ¹íˆ 0.3ì€ ê½¤ ê°•í•˜ê²Œ ë–¨ì–´ëœ¨ë¦¬ëŠ” í¸)

2. SoftmaxëŠ” ì–´ë–¤ ì›ë¦¬ë¡œ í´ë˜ìŠ¤ í•˜ë‚˜ë¥¼ ì„ íƒ?
ğŸ‘‰ ì¶œë ¥ê°’(ë¡œì§“)ì„ í™•ë¥ ì²˜ëŸ¼ ë³€í™˜í•´ì„œ, ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ë¥¼ ì„ íƒ
ë””í…Œì¼í•˜ê²Œ ë³´ë©´:
ë§ˆì§€ë§‰ Dense ì¸µì€ ê° í´ë˜ìŠ¤ì— ëŒ€í•œ "ë¡œì§“ (logit)"ì„ ì¶œë ¥ (ê·¸ëƒ¥ ì ìˆ˜ ê°™ì€ ê°’)
SoftmaxëŠ” ì´ ë¡œì§“ë“¤ì„ "í™•ë¥  ë¶„í¬"ì²˜ëŸ¼ ë³€í™˜
ìˆ˜ì‹ì„ í†µí•´ ê³„ì‚° í›„ np.argmaxë¥¼ ì¨ì„œ ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í´ë˜ìŠ¤ë¥¼ ìµœì¢… ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì„ íƒ

3. EarlyStoppingì€ ì–´ë–»ê²Œ í•™ìŠµì„ ë©ˆì¶”ëŠ” ê¸°ì¤€ì„ ì¡ëŠ”ê±¸ê¹Œ?
ğŸ‘‰ validation ë°ì´í„°ì— ëŒ€í•´ ë” ì´ìƒ ì„±ëŠ¥ì´ ì¢‹ì•„ì§€ì§€ ì•Šìœ¼ë©´ í•™ìŠµì„ ë©ˆì¶”ëŠ” ê¸°ìˆ ì´ì•¼.

êµ¬ì²´ì ìœ¼ë¡œ:
monitor='val_loss': validation setì— ëŒ€í•œ lossë¥¼ ì§€ì¼œë´„
patience=5: ë§Œì•½ 5ë²ˆ ì—°ì† validation lossê°€ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ ë©ˆì¶¤
ì¦‰, "validation lossê°€ 5ë²ˆ ì—í­ ë™ì•ˆ ê³„ì† ì¤„ì§€ ì•Šìœ¼ë©´ â†’ ê³¼ì í•©ì´ ì‹œì‘ëë‹¤ê³  íŒë‹¨ â†’ í•™ìŠµ ì¤‘ë‹¨"
ì¶”ê°€ë¡œ, restore_best_weights=True ì˜µì…˜ ë•ë¶„ì—, ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì•˜ë˜ ì‹œì ì˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¡œ ìë™ìœ¼ë¡œ ë³µì›
"""
"""
Weighted F1 Score: 0.9863
Classification Report:
              precision    recall  f1-score   support

           0       0.98      1.00      0.99       663
           1       0.97      0.96      0.97       304
           2       0.99      1.00      1.00      2186
           3       0.88      0.79      0.83        19
           4       1.00      0.98      0.99       668
           5       0.95      0.95      0.95       128
           6       0.75      0.66      0.70        32

    accuracy                           0.99      4000
   macro avg       0.93      0.90      0.92      4000
weighted avg       0.99      0.99      0.99      4000

âœ… Weighted F1 Score: 0.9874
Weighted F1ëŠ” í´ë˜ìŠ¤ë³„ ë°ì´í„° ìˆ˜ ë¹„ìœ¨ì„ ê³ ë ¤í•´ì„œ í‰ê· ë‚¸ F1 ìŠ¤ì½”ì–´ì•¼.

0.9874ë©´ ê±°ì˜ ì™„ë²½ì— ê°€ê¹Œìš´ ì„±ëŠ¥ì´ë¼ëŠ” ëœ»ì´ì•¼.

ëª¨ë¸ì´ ì „ì²´ì ìœ¼ë¡œ í´ë˜ìŠ¤ë§ˆë‹¤ ì˜ ë§ì¶˜ë‹¤ëŠ” ì–˜ê¸°ì§€.

âœ… Classification Report í•´ì„
(í´ë˜ìŠ¤ë³„ Precision, Recall, F1-Score, Support)


í´ë˜ìŠ¤	precision	recall	f1-score	support (ê°œìˆ˜)	í•´ì„
0ë²ˆ	0.99	0.98	0.98	663	ê±°ì˜ ì™„ë²½í•˜ê²Œ ì˜ˆì¸¡í•¨
1ë²ˆ	0.97	0.99	0.98	419	ì•½ê°„ precisionì´ recallë³´ë‹¤ ë‚®ì§€ë§Œ ì—­ì‹œ í›Œë¥­
2ë²ˆ	0.99	1.00	0.99	2186	ì••ë„ì ìœ¼ë¡œ ì •í™•í•¨ (íŠ¹íˆ 2ë²ˆ í´ë˜ìŠ¤ ë°ì´í„° ë§ìŒ)
3ë²ˆ	1.00	0.63	0.77	19	precisionì€ ì¢‹ì€ë°, recallì´ ë‚®ìŒ â†’ ì‹¤ì œ 3ë²ˆì¸ë° ë‹¤ë¥¸ í´ë˜ìŠ¤ë¡œ ì°©ê°í•œ ê²½ìš° ìˆìŒ
4ë²ˆ	0.99	0.99	0.99	668	ì—­ì‹œ ì™„ë²½ì— ê°€ê¹Œì›€
5ë²ˆ	0.92	0.78	0.84	45	5ë²ˆ í´ë˜ìŠ¤ê°€ ìƒëŒ€ì ìœ¼ë¡œ ì–´ë ¤ìš´ í¸ (ë°ì´í„° ì ìŒ + í—·ê°ˆë¦¼)
âœ… Accuracy (ì •í™•ë„)
ì „ì²´ ë°ì´í„° 4000ê°œ ì¤‘ì— 99% ì •í™•ë„ë¡œ ë§ì·„ì–´.

í•™ìŠµ, í…ŒìŠ¤íŠ¸ ëª¨ë‘ ì˜¤ë²„í”¼íŒ… ì—†ì´ ë§¤ìš° ì˜ ëœ ëŠë‚Œì´ì•¼.

âœ… Macro avg vs Weighted avg
macro avg: ë‹¨ìˆœ í‰ê·  (ëª¨ë“  í´ë˜ìŠ¤ ë¹„ì¤‘ ë˜‘ê°™ì´)

Precision 0.98, Recall 0.89, F1 0.93

weighted avg: ë°ì´í„° ê°œìˆ˜ ê³ ë ¤í•´ì„œ í‰ê· 

Precision 0.99, Recall 0.99, F1 0.99

â†’ ìš”ì•½: ë°ì´í„° ë§ì€ í´ë˜ìŠ¤ë“¤ì´ ì˜ ë§ì¶°ì¡Œê³ , ë°ì´í„° ì ì€ í´ë˜ìŠ¤ëŠ” ì‚´ì§ recallì´ ë–¨ì–´ì§„ë‹¤.
â†’ íŠ¹íˆ 3ë²ˆ, 5ë²ˆ í´ë˜ìŠ¤ê°€ recallì—ì„œ ì•½ê°„ ì†í•´ë³¸ë‹¤.

âœ… ì´í‰
ì „ì²´ì ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥ ë§¤ìš° ì¢‹ìŒ.

2ë²ˆ, 0ë²ˆ, 4ë²ˆ í´ë˜ìŠ¤ëŠ” ì •ë§ ì˜ ë§ì¶˜ë‹¤.

3ë²ˆ, 5ë²ˆ í´ë˜ìŠ¤ëŠ” ìƒ˜í”Œ ìˆ˜ê°€ ì ê±°ë‚˜, íŠ¹ì§•ì´ ë¹„ìŠ·í•´ì„œ ì‚´ì§ í—·ê°ˆë¦¬ëŠ” ë¬¸ì œê°€ ìˆë‹¤.

ê°œì„ í•˜ë ¤ë©´:

3ë²ˆ, 5ë²ˆ í´ë˜ìŠ¤ ë°ì´í„° ì–‘ì„ ëŠ˜ë¦¬ê±°ë‚˜

í´ë˜ìŠ¤ ê°„ êµ¬ë¶„ í¬ì¸íŠ¸ë¥¼ ì¢€ ë” ê°•ì¡°í•´ì£¼ëŠ” íŠ¹ì§•(Feature)ì„ ì¶”ê°€í•˜ë©´ ì¢‹ì„ ë“¯!
"""
# 6-1. ë”¥ëŸ¬ë‹ ëª¨ë¸ ë§Œë“¤ê¸°
nn_model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(len(np.unique(y_encoded)), activation='softmax')  # í´ë˜ìŠ¤ ê°œìˆ˜ ë§Œí¼
])

nn_model.compile(optimizer='adam',
                 loss='sparse_categorical_crossentropy',
                 metrics=['accuracy'])

# 6-2. ë”¥ëŸ¬ë‹ í•™ìŠµ
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = nn_model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=100,
    batch_size=32,
    callbacks=[early_stopping],
    verbose=1
)

# 6-3. ë”¥ëŸ¬ë‹ í‰ê°€
nn_preds = np.argmax(nn_model.predict(X_test), axis=1)

print("Neural Network Classification Report")
print(classification_report(y_test, nn_preds, target_names=le_body.classes_))

# 1. ëª¨ë¸ ì˜ˆì¸¡
y_pred_probs = nn_model.predict(X_test)
y_pred_classes = np.argmax(y_pred_probs, axis=1)  # í™•ë¥  -> í´ë˜ìŠ¤ ì„ íƒ
y_true_classes = y_test  # ê·¸ëƒ¥ y_test ì‚¬ìš©

# 2. Confusion Matrix ê³„ì‚°
cm = confusion_matrix(y_true_classes, y_pred_classes)

# 3. Confusion Matrix ì‹œê°í™”
plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=le_body.classes_, yticklabels=le_body.classes_)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# 4. Classification Report ì¶œë ¥
print("Classification Report:")
print(classification_report(y_true_classes, y_pred_classes, target_names=le_body.classes_))

# 5. F1 Score ì¶œë ¥
from sklearn.metrics import f1_score

f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')
print(f"Weighted F1 Score: {f1:.4f}")

# 6-4. ë”¥ëŸ¬ë‹ í˜¼ë™í–‰ë ¬ ì‹œê°í™”
plt.figure(figsize=(8,6))
sns.heatmap(confusion_matrix(y_test, nn_preds), annot=True, fmt='d', cmap='Greens',
            xticklabels=le_body.classes_, yticklabels=le_body.classes_)
plt.title('Neural Network Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

# 6-5. í•™ìŠµ ê³¼ì • ì‹œê°í™” (Loss, Accuracy)
plt.figure(figsize=(14,5))

# Loss
plt.subplot(1,2,1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title('Loss Over Epochs')

# Accuracy
plt.subplot(1,2,2)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.title('Accuracy Over Epochs')

plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

# 1. ëª¨ë¸ ì˜ˆì¸¡
y_pred_probs = nn_model.predict(X_test)
y_pred_classes = np.argmax(y_pred_probs, axis=1)  # í™•ë¥  -> í´ë˜ìŠ¤ ì„ íƒ
y_true_classes = y_test  # ì—¬ê¸°! ê·¸ëƒ¥ y_testë¥¼ ê·¸ëŒ€ë¡œ ì¨

# 2. Confusion Matrix ê³„ì‚°
cm = confusion_matrix(y_true_classes, y_pred_classes)

# 3. Confusion Matrix ì‹œê°í™”
plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# 4. Classification Report ì¶œë ¥
print("Classification Report:")
print(classification_report(y_true_classes, y_pred_classes))
