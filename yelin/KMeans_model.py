import matplotlib.pyplot as plt
import numpy as np
from sklearn.cluster import KMeans
import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.utils import resample
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import MinMaxScaler
import pandas as pd


# 1. íŒŒì¼ ì½ê¸°
df = pd.read_csv("../renttherunway_data.csv")

# 2. ì‚¬ìš©í•  íŠ¹ì„±ë“¤ë§Œ ë½‘ê¸°
data = df[['fit', 'user_id', 'item_id', 'weight', 'rating', 'body type', 'height', 'size', 'age']].copy()

# 3. ì»¬ëŸ¼ëª… ë³€ê²½
data.rename(columns={
    'weight':'weight (kg)',
    'body type':'body_type',
    'height':'height (cm)'
}, inplace=True)

# 4. ë‹¨ìœ„ ë³€í™˜ í•¨ìˆ˜ ì •ì˜
def lb_to_kg_trans(lb_str):
    if isinstance(lb_str, str) and 'lbs' in lb_str:
        number = int(lb_str.replace('lbs', '').strip())
        return round(number * 0.453592, 2)
    return None

def height_trans(height):
    if pd.isna(height):
        return height
    if isinstance(height, str) and "'" in height and "\"" in height:
        feet = float(height.split("'")[0]) * 30.48
        inch = float(height.split("'")[1].replace("\"", "").strip()) * 2.54
        return feet + inch
    return None

def rating_scale_trans(rating):
    return rating / 2

# 5. ë‹¨ìœ„ ë³€í™˜ ì ìš©
data['weight (kg)'] = data['weight (kg)'].apply(lb_to_kg_trans)
data['height (cm)'] = data['height (cm)'].apply(height_trans)
data['rating'] = data['rating'].apply(rating_scale_trans)

# 'fit' ì»¬ëŸ¼ì—ì„œ 'fit'ì´ ì•„ë‹Œ ê°’ì„ ê°€ì§„ í–‰ ì‚­ì œ
# data = data[data['fit'] == 'fit']
# ë§¤í•‘
fit_mapping = {
    'small' : 0,
    'fit' : 2,
    'large' : 1
}
data['fit'] = data.loc[:, 'fit'].map(fit_mapping)

# 6. ì›í•« ì¸ì½”ë”© (ì´ íƒ€ì´ë°ì— ì§„í–‰í•´ì•¼ ì´í›„ body_type ì»¬ëŸ¼ì´ ì‚¬ë¼ì§„ ê±¸ ì¸ì§€ ê°€ëŠ¥)
data = pd.get_dummies(data, columns=['body_type'])
# data = pd.get_dummies(data, columns=['fit', 'body_type'])

# 7. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
# - weightëŠ” ê°™ì€ size í‰ê· ìœ¼ë¡œ ì±„ìš°ê¸°
size_weight_means = data.groupby('size')['weight (kg)'].mean()
def fill_weight(row):
    if pd.isna(row['weight (kg)']):
        return size_weight_means.get(row['size'], None)
    else:
        return row['weight (kg)']
data['weight (kg)'] = data.apply(fill_weight, axis=1)

# - ë‚˜ë¨¸ì§€ ìˆ˜ì¹˜í˜• í‰ê· ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
# data['weight (kg)'] = data['weight (kg)'].fillna(data['weight (kg)'].mean())
# data['height (cm)'] = data['height (cm)'].fillna(data['height (cm)'].mean())
# data['rating'] = data['rating'].fillna(data['rating'].mean())
# data['age'] = data['age'].fillna(data['age'].mean())
data = data.dropna(subset=['weight (kg)', 'height (cm)', 'rating', 'age'])
print(data)
data = data[data['fit'] == 2]
data = data[data['rating'] == 5]

df = pd.read_csv('../renttherunway_data.csv')

# # ìŠ¤ì¼€ì¼ ì¡°ì •

"""
ì¢‹ì€ ì§ˆë¬¸ì´ì•¼! ì¼ë°˜ì ìœ¼ë¡œëŠ” ìŠ¤ì¼€ì¼ë§ì„ í•˜ë©´ KMeansë‚˜ ë‹¤ë¥¸ ê±°ë¦¬ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì˜ ì„±ëŠ¥ì´ ì˜¬ë¼ê°€ëŠ” ê²½ìš°ê°€ ë§ì•„, í•˜ì§€ë§Œ ì§€ê¸ˆì²˜ëŸ¼ ìŠ¤ì¼€ì¼ë§ì„ í–ˆë”ë‹ˆ ì˜¤íˆë ¤ Silhouette Scoreê°€ ë–¨ì–´ì§€ëŠ” ê²½ìš°ëŠ” ì¢…ì¢… ë°œìƒí•  ìˆ˜ ìˆì–´. ì™œ ê·¸ëŸ°ì§€ ì•„ë˜ì— ì´ìœ ë“¤ì„ ì •ë¦¬í•´ì¤„ê²Œ.

âœ… KMeansì—ì„œ ìŠ¤ì¼€ì¼ë§ì´ ì¤‘ìš”í•œ ì´ìœ 
KMeansëŠ” ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬(Euclidean Distance) ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì´ë¼ì„œ ê° featureì˜ ê°’ì˜ í¬ê¸° ì°¨ì´ê°€ í´ ê²½ìš°, í° ê°’ì„ ê°€ì§€ëŠ” featureì— í´ëŸ¬ìŠ¤í„°ë§ì´ í¸í–¥ë˜ê¸° ì‰¬ì›Œ. ê·¸ë˜ì„œ ë³´í†µ ìŠ¤ì¼€ì¼ë§ì€ ë„ì›€ì´ ë¼.

í•˜ì§€ë§Œ!

ğŸ” ë„ˆì˜ ê²½ìš°ì²˜ëŸ¼ ìŠ¤ì¼€ì¼ë§ í›„ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” ì´ìœ ë“¤
1. ìŠ¤ì¼€ì¼ë§ ìì²´ê°€ feature ì˜ë¯¸ë¥¼ ë‚ ë ¤ë²„ë ¸ì„ ìˆ˜ ìˆìŒ
ì˜ˆë¥¼ ë“¤ì–´ fit, size, rating, weight, height ë“±ì˜ ì»¬ëŸ¼ì€ ì„œë¡œ ì˜ë¯¸ì ìœ¼ë¡œ ë‹¤ë¥´ê³ , íŠ¹íˆ fitì´ë‚˜ sizeëŠ” ë³¸ì§ˆì ìœ¼ë¡œ ë²”ì£¼í˜• ë˜ëŠ” ìˆœì„œí˜• ë³€ìˆ˜ì•¼.

ğŸ‘‰ ê·¼ë° ì´ê±¸ StandardScalerë¡œ ìŠ¤ì¼€ì¼ë§í•˜ë©´ ë‹¨ìˆœíˆ í‰ê·  0, ë¶„ì‚° 1ë¡œ ë³€í™˜ë˜ê¸° ë•Œë¬¸ì—, í´ëŸ¬ìŠ¤í„°ë§ì—ì„œ ì˜ë¯¸ ìˆëŠ” ì •ë³´ê°€ í¬ì„ë  ìˆ˜ ìˆì–´.

ì˜ˆ:

fit=2 (ì •ì‚¬ì´ì¦ˆ), fit=0 (ì‘ë‹¤)ëŠ” ì˜ë¯¸ìƒ ì—„ì²­ ë‹¤ë¥´ì§€ë§Œ, ìŠ¤ì¼€ì¼ í›„ì—” ë‹¨ì§€ ì •ê·œë¶„í¬ ìƒì˜ ìˆ˜ì¹˜ì¼ ë¿ì„.

2. ìŠ¤ì¼€ì¼ë§ì´ êµ°ì§‘ ê°„ ê²½ê³„ë¥¼ ë¬´ë„ˆëœ¨ë¦¼
ì›ë˜ëŠ” í´ëŸ¬ìŠ¤í„°ë“¤ì´ íŠ¹ì • feature ê¸°ì¤€ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ êµ¬ë¶„ë˜ê³  ìˆì—ˆëŠ”ë°, ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ feature ê°„ ìƒëŒ€ì ì¸ ê±°ë¦¬ êµ¬ì„±ì´ ë°”ë€Œë©´ì„œ êµ°ì§‘ ê°„ ê²½ê³„ê°€ ëª¨í˜¸í•´ì§€ëŠ” ê²½ìš°ë„ ìˆì–´.

3. ìŠ¤ì¼€ì¼ëœ ê°’ìœ¼ë¡œëŠ” ì‚¬ëŒì´ í•´ì„í•˜ê¸° ì–´ë µë‹¤
ìŠ¤ì¼€ì¼ ì „ì—” weightë‚˜ size ê°™ì€ ì»¬ëŸ¼ì´ ì§ê´€ì ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„° ì°¨ì´ë¥¼ ë³´ì—¬ì¤„ ìˆ˜ ìˆì—ˆëŠ”ë°, ìŠ¤ì¼€ì¼ í›„ì—” ëª¨ë‘ ì¶”ìƒì ì¸ ìˆ«ìë¼ì„œ í´ëŸ¬ìŠ¤í„°ì˜ íŠ¹ì„±ì„ êµ¬ë¶„í•˜ê¸° ì–´ë ¤ì›€ â†’ ì´ë¡œ ì¸í•´ silhouette scoreë„ ì €í•˜.

4. rating, fit ë“±ì˜ ë²”ì£¼í˜• ê°’ê¹Œì§€ ìŠ¤ì¼€ì¼ë§í•´ì„œ ìƒê¸´ ë¶€ì‘ìš©
KMeansëŠ” ì—°ì†í˜• ìˆ˜ì¹˜ì— ê°•í•œë°, ë²”ì£¼í˜• ì •ë³´ê°€ ìŠ¤ì¼€ì¼ë§ë˜ë©´ ì˜ë¯¸ ì—†ëŠ” ê±°ë¦¬ ê³„ì‚°ì´ ì´ë¤„ì§ˆ ìˆ˜ ìˆì–´.

ì˜ˆ:

fit = 0, 1, 2ëŠ” ìˆ«ìì²˜ëŸ¼ ë³´ì—¬ë„ ë²”ì£¼í˜•ì¸ë°, ìŠ¤ì¼€ì¼ëŸ¬ëŠ” ì´ê±¸ ì—°ì†í˜•ìœ¼ë¡œ ì²˜ë¦¬í•¨ â†’ ë¬¸ì œê°€ ìƒê¹€.


"""
# data = data.drop(columns=['user_id', 'item_id', 'rating', 'body_type_apple', 'body_type_athletic',
#        'body_type_full bust', 'body_type_hourglass', 'body_type_pear',
#        'body_type_petite', 'body_type_straight & narrow'])
original_df = data.copy()
sc = MinMaxScaler()
scaled_array = sc.fit_transform(original_df)
scaled_df = pd.DataFrame(scaled_array, columns=original_df.columns)

# original_df = data.copy()
# sc = StandardScaler()
# scaled_array = sc.fit_transform(original_df)
# scaled_df = pd.DataFrame(scaled_array, columns=original_df.columns)

"""# ìƒê´€ ê´€ê³„ í™•ì¸
def corr_analysis(corr_input):
    if 0.0 <= corr_input <= 0.1:
        print("ê±°ì˜ ìƒê´€ ì—†ìŒ")
    elif 0.1 < corr_input <= 0.3:
        print("ì•½í•œ ìƒê´€ê´€ê³„ (weak)")
    elif 0.3 < corr_input <= 0.7:
        print("ì¤‘ê°„ ì •ë„ ìƒê´€ê´€ê³„ (moderate)")
    elif 0.7 < corr_input <= 1.0:
        print("ê°•í•œ ìƒê´€ê´€ê³„ (strong)")
    else:
        print("ìƒê´€ê³„ìˆ˜ ê°’ì´ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.")
print(scaled_df.columns)

# ìƒê´€ê´€ê³„ ë¶„ì„ ëŒ€ìƒ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
columns = [col for col in scaled_df.columns]

# ëª¨ë“  ìŒ ì¡°í•©ì„ ìƒì„±í•´ì„œ ë¹„êµ
from itertools import combinations
for col1, col2 in combinations(columns, 2):
    corr = scaled_df[col1].corr(scaled_df[col2])
    print(f"[{col1} / {col2}] ìƒê´€ ê³„ìˆ˜: {corr:.4f}")
    corr_analysis(corr)
    print("-" * 60)
import matplotlib.pyplot as plt
import seaborn as sns

# ì‹œê°í™”í•  ì»¬ëŸ¼ë§Œ ì¶”ë¦¼ (í•„ìš” ì‹œ user_id, item_id ê°™ì€ ì»¬ëŸ¼ì€ ì œê±°)
exclude_cols = ['user_id', 'item_id']
columns = [col for col in scaled_df.columns if col not in exclude_cols]

# ìƒê´€ê³„ìˆ˜ í–‰ë ¬ ìƒì„±
corr_matrix = scaled_df[columns].corr()

# íˆíŠ¸ë§µ ì‹œê°í™”
plt.figure(figsize=(14, 12))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", square=True,
            linewidths=0.5, cbar_kws={"shrink": 0.7})
plt.title("ğŸ“Š Feature Correlation Heatmap", fontsize=16)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()"""

print(data.columns)
# ìƒ˜í”Œë§
# sampled_data = resample(scaled_df, n_samples=50000, random_state=42)
# sampled_data = sampled_data.drop(columns=['user_id', 'item_id', 'rating'])
# sampled_data = sampled_data[['height (cm)','weight (kg)', 'size', 'item_id', 'rating', 'fit']]
# sampled_data = sampled_data[['height (cm)', 'weight (kg)', 'size']]
# print(sampled_data)

# í•™ìŠµ
k=20
km = KMeans(n_clusters=k, random_state=42, init='k-means++')
km.fit(scaled_df)
labels = km.labels_
score = silhouette_score(scaled_df, labels)
print("[",k,"] score: ", score)
print(km.n_clusters)

import seaborn as sns

# KMeans í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ sampled_dataì— ì¶”ê°€
scaled_df['cluster'] = labels

# í´ëŸ¬ìŠ¤í„°ë§ëœ ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(10, 8))
sns.scatterplot(data=scaled_df, x='weight (kg)', y='height (cm)', hue='cluster', palette='viridis', s=100, alpha=0.7, edgecolor='black')
plt.title(f"KMeans Clustering Results (k={k})", fontsize=16)
plt.xlabel("Weight (kg)")
plt.ylabel("Size")
plt.legend(title='Cluster', loc='best')
plt.tight_layout()
plt.show()
# ========================================
# ğŸ“ˆ ìµœì  k ì°¾ê¸° (Elbow + Silhouette Score)
# ========================================

# inertias = []
# silhouette_scores = []
# K_range = range(2, 20)  # ì¼ë°˜ì ìœ¼ë¡œ 2~10 ì‚¬ì´ì—ì„œ íƒìƒ‰
#
# for k in K_range:
#     km = KMeans(n_clusters=k, random_state=42)
#     km.fit(sampled_data)
#     inertias.append(km.inertia_)
#
#     labels = km.labels_
#     score = silhouette_score(sampled_data, labels)
#     silhouette_scores.append(score)
#     print("k: ",k,", score: ", score)
#
# # ğŸ“Š ê·¸ë˜í”„ ì¶œë ¥
# plt.figure(figsize=(14, 5))
#
# # 1. Elbow Method
# plt.subplot(1, 2, 1)
# plt.plot(K_range, inertias, 'o-', color='blue')
# plt.xlabel('Number of Clusters (k)')
# plt.ylabel('Inertia')
# plt.title('Elbow Method')
# plt.grid(True)
#
# # 2. Silhouette Score
# plt.subplot(1, 2, 2)
# plt.plot(K_range, silhouette_scores, 'o-', color='green')
# plt.xlabel('Number of Clusters (k)')
# plt.ylabel('Silhouette Score')
# plt.title('Silhouette Score by k')
# plt.grid(True)
#
# plt.tight_layout()
# plt.show()

